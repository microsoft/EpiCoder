{"idx": 0, "original_code": "''' Unsupervised Out-of-distribution Detection Procedure in Pytorch.\n\nReference:\n[Yu et al. ICCV 2019] Unsupervised Out-of-Distribution Detection by Maximum Classifier Discrepancy (https://arxiv.org/abs/1908.04951)\n'''\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\n# Python\nimport random\n\n# Torch\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader\nimport torch.optim.lr_scheduler as lr_scheduler\nfrom torch.utils.data.sampler import SubsetRandomSampler\n\n# Torchvison\nfrom torchvision.utils import make_grid\nimport torchvision.transforms as T\nfrom torchvision.datasets import CIFAR10, MNIST\n\n# Utils\nimport visdom\n\n# Custom\nimport backbone.densenet as densenet\nfrom config import *\nfrom data.datasets import UnsupData\nfrom utils import *\n\n\n##\n# Data\ntrain_transform = T.Compose([\n    T.RandomHorizontalFlip(),\n    T.RandomCrop(size=32, padding=4),\n    T.ToTensor(),\n    T.Normalize([0.4914, 0.4822, 0.4465], [0.2023, 0.1994, 0.2010]) # T.Normalize((0.5071, 0.4867, 0.4408), (0.2675, 0.2565, 0.2761)) # CIFAR-100\n])\n\ntest_transform = T.Compose([\n    T.ToTensor(),\n    T.Normalize([0.4914, 0.4822, 0.4465], [0.2023, 0.1994, 0.2010]) # T.Normalize((0.5071, 0.4867, 0.4408), (0.2675, 0.2565, 0.2761)) # CIFAR-100\n])\n\ncifar10_train = CIFAR10('../cifar10', train=True, \n                        download=False, transform=train_transform)\ncifar10_val   = CIFAR10('../cifar10', train=False, \n                        download=False, transform=test_transform)\ncifar10_test  = CIFAR10('../cifar10', train=False, \n                        download=False, transform=test_transform)\n    \n#unsup_train = UnsupData(ood='../Imagenet_resize/Imagenet_resize', \n#                        id='../cifar10', train=True, \n#                        transform=train_transform)\n#unsup_val = UnsupData(ood='../Imagenet_resize/Imagenet_resize', \n#                      id='../cifar10', train=False, \n#                      transform=test_transform)\n# MNIST('../mnist', train=False, download=True) # Download MNIST test data\nunsup_train = UnsupData(ood='../mnist', id='../cifar10', train=True, transform=train_transform)\nunsup_val = UnsupData(ood='../mnist', id='../cifar10', train=False, transform=test_transform)\n\n##\n# Main\nif __name__ == '__main__':\n    # Visdom visualizer\n    vis = visdom.Visdom(server='http://localhost')\n    plot_data = {'X': [], 'Y': [], 'legend': ['Loss']}\n\n    # Dataloaders\n    indices = list(range(10000))\n    random.Random(4).shuffle(indices)\n    train_loader = DataLoader(cifar10_train, batch_size=BATCH,\n                              shuffle=True, pin_memory=True, \n                              drop_last=True, num_workers=2)\n    val_loader = DataLoader(cifar10_val, batch_size=BATCH,\n                            sampler=SubsetRandomSampler(indices[:NUM_VAL]),\n                            pin_memory=True, num_workers=2)\n    test_loader = DataLoader(cifar10_test, batch_size=BATCH,\n                             shuffle=SubsetRandomSampler(indices[NUM_VAL:]), \n                             pin_memory=True, num_workers=2)\n    unsup_train_loader = DataLoader(unsup_train, batch_size=BATCH,\n                                    shuffle=True, pin_memory=True, \n                                    drop_last=True, num_workers=2)\n    unsup_val_loader = DataLoader(unsup_val, batch_size=BATCH,\n                                  shuffle=False, pin_memory=True, \n                                  num_workers=2)\n    dataloaders  = {'sup_train': train_loader, \n                    'sup_val': val_loader, \n                    'sup_test': test_loader, \n                    'unsup_train': list(unsup_train_loader), \n                    'unsup_val': unsup_val_loader}\n\n    # Model\n    two_head_net = densenet.densenet_cifar().cuda()\n    torch.backends.cudnn.benchmark = True\n\n    # Losses\n    sup_criterion = nn.CrossEntropyLoss()\n    unsup_criterion = DiscrepancyLoss\n    criterions = {'sup': sup_criterion, 'unsup': unsup_criterion}\n\n    \"\"\" Data visualization\n    \"\"\"\n    inputs, classes = next(iter(dataloaders['unsup_train']))\n    out = make_grid(inputs)\n    imshow(out, title='')\n\n    \"\"\" Pre-training\n    optimizer = optim.SGD(two_head_net.parameters(), lr=LR, \n                          momentum=MOMENTUM, weight_decay=WDECAY)\n    scheduler = lr_scheduler.MultiStepLR(optimizer, milestones=MILESTONES)\n\n    train(two_head_net, criterions, optimizer, \n          scheduler, dataloaders, EPOCH, vis, plot_data)\n          \n    acc_1, acc_2 = test(two_head_net, dataloaders, mode='sup_test')\n    print('Test acc {}, {}'.format(acc_1, acc_2)) # > 92.5\n\n    test3(two_head_net, dataloaders, mode='unsup_train')\n\n    # Save a checkpoint\n    torch.save({\n        'epoch': EPOCH,\n        'accuracy': (acc_1 + acc_2) / 2,\n        'state_dict': two_head_net.state_dict()\n    },\n    './ckp_weights/pre-train/weights/two_head_cifar10.pth')\n    \"\"\"\n\n    \"\"\" Fine-tuning\n    \"\"\"\n    checkpoint = torch.load('./ckp_weights/pre-train/weights/two_head_cifar10.pth')\n    two_head_net.load_state_dict(checkpoint['state_dict'])\n \n    optimizer = optim.SGD(two_head_net.parameters(), \n                          lr=0.001,\n                          momentum=MOMENTUM, weight_decay=WDECAY)\n    # the scheduler is not necessary in the fine-tuning step, but it is made just in case.\n    scheduler = lr_scheduler.MultiStepLR(optimizer, milestones=MILESTONES) \n    \n    fine_tune(two_head_net, criterions, optimizer, \n              scheduler, dataloaders, num_epochs=10, vis=vis)\n\n    \"\"\" Discrepancy distribution of ID and OOD\n    \"\"\"\n    checkpoint = torch.load('./ckp_weights/fine-tune/weights/unsup_ckp.pth')\n    two_head_net.load_state_dict(checkpoint['state_dict'])\n\n    test2(two_head_net, dataloaders, mode='unsup_train')", "features": {"programming language": ["Python"], "workflow": ["data loading", "data transformation", "visualization", "model initialization", "loss definition", "training", "validation", "testing", "model saving", "fine-tuning"], "implementation style": ["procedural", "object-oriented"], "functionality": ["unsupervised out-of-distribution detection"], "resource usage": ["CPU Cycles", "GPU ComputeOperations"], "computation operation": {"mathematical operation": ["cross-entropy loss"], "algorithmic operation": ["stochastic gradient descent", "learning rate scheduling"]}, "security": [], "user interaction": {"display": ["visualize data using Visdom"]}, "data processing": {"data preparation": ["random horizontal flip", "random crop", "normalize"], "data retrieval": ["fetching CIFAR10 dataset", "fetching MNIST dataset"], "data transformation": ["convert to tensor", "normalize"], "data validation": [], "string manipulation": []}, "file operation": ["file save", "file load"], "error handling": [], "logging": [], "dependency relations": ["torch", "torchvision", "visdom"], "algorithm": ["SGD", "MultiStepLR"], "data structures": ["tensor", "list", "dict"], "implementation logic": ["loop", "conditional"], "advanced techniques": ["unsupervised learning", "OOD detection", "deep learning"], "issues & bugs": [], "potential scenario": "The code is used for detecting out-of-distribution data points in datasets like CIFAR10 and MNIST using unsupervised learning techniques.", "summary": "Implements an unsupervised out-of-distribution detection method using a deep learning model, with data transformation, training, and evaluation steps.", "purpose": "To detect out-of-distribution data points using unsupervised learning with a deep learning model."}}
{"idx": 1, "original_code": "\n# Custom Model-From in django-admin demo \nQ:\nclass Person(Model):\n  first_name = CharField(...)\n  last_name = CharField(...)\n  def name():\n    return first_name + ' ' + last_name\n'''\n    Displaying the name as a single column in the admin change list is easy enough. However, \n    I need a single, editable \"name\" field that is editable from the list page, \n    which I can then parse to extract and set the model field values. The parsing isn't a concern. \n    I am just wondering how to have an editable form field on the list page \n    that doesn't correspond directly to a model field.\n'''\n\nA:\nclass PersonChangeListForm(forms.ModelForm):\n    class Meta:\n        model = Person\n    name = forms.CharField()\n\n    def __init__(self, *args, **kwargs):\n        instance = kwargs.get('instance')\n        if instance:\n            initial = kwargs.get('initial', {})\n            initial['name'] = '%s %s' % (instance.first_name, instance.last_name)\n            kwargs['initial'] = initial\n        super(PersonChangeListForm, self).__init__(*args, **kwargs)\n\n    def save(self, *args, **kwargs):\n        # use whatever parsing you like here\n        first_name, last_name = self.cleaned_data['name'].split(None, 1)\n        self.cleaned_data['first_name'] = first_name\n        self.cleaned_data['last_name'] = last_name\n        super(PersonChangeListForm, self).save(*args, **kwargs)\n\nclass PersonAdmin(admin.ModelAdmin):\n    def get_changelist_form(self, request, **kwargs):\n        return PersonChangeListForm\n\n\n\n\n\n'''\n# compilemessages\n\ndjango-admin compilemessages\nCompiles .po files created by makemessages to .mo files for use with the built-in gettext support. \n\n---------------------------------------------------------------------------------------------------\n\n# makemessages\n\ndjango-admin makemessages\nRuns over the entire source tree of the current directory and pulls out all strings \nmarked for translation. It creates (or updates) a message file in the conf/locale (in the Django tree) \nor locale (for project and application) directory. After making changes to the messages files \nyou need to compile them with compilemessages for use with the builtin gettext support. \nSee the i18n documentation for details.\n'''\n\n\n\n\n", "features": {"programming language": ["Python"], "workflow": ["define model", "create form", "customize admin interface", "compile translation messages"], "implementation style": ["object-oriented"], "functionality": ["user interface customization", "internationalization"], "resource usage": ["CPU Cycles"], "computation operation": [], "security": [], "user interaction": {"UIComponents": ["editable form field in admin"], "Display": ["single column name in admin change list"]}, "data processing": {"data transformation": ["concatenate strings", "split strings"], "data validation": ["validate form data"]}, "file operation": ["compile .po files", "create/update message files"], "error handling": ["validate form data"], "logging": [], "dependency relations": ["django", "gettext"], "algorithm": [], "data structures": ["string", "model"], "implementation logic": ["conditional"], "advanced techniques": [], "issues & bugs": [], "potential scenario": "The code is used in a Django application to customize the admin interface for managing Person objects, allowing for a single, editable 'name' field in the admin list view and handling internationalization through message file compilation.", "summary": "The code provides a customized admin interface for Django models, allowing for editable fields that combine multiple model attributes, and handles internationalization by compiling translation messages.", "purpose": "To customize the Django admin interface to allow editing of a combined 'name' field and support internationalization."}}
{"idx": 2, "original_code": "system.exec_command(\"killall java\", False)", "features": {"programming language": ["Python"], "workflow": ["execute command"], "implementation style": ["procedural"], "functionality": ["system control"], "resource usage": ["CPU Cycles"], "computation operation": [], "security": [], "user interaction": [], "data processing": [], "file operation": [], "error handling": [], "logging": [], "dependency relations": [], "algorithm": [], "data structures": ["string"], "implementation logic": ["conditional"], "advanced techniques": [], "issues & bugs": [], "potential scenario": "The code is used to terminate all running Java processes on a Unix-like system.", "summary": "Executes a system command to kill all running Java processes.", "purpose": "To stop all instances of Java processes running on the system."}}
{"idx": 3, "original_code": "\nShould compose two functions together\n| (def inc (x) (+ x 1))\n> ((pipe inc inc) -1)\n= 1\n\nShould compose several functions together\n| (def inc (x) (+ x 1))\n| (def half (x) (/ x 2))\n> ((pipe inc inc inc half) 1)\n= 2\n\nShould compose closures together\n> ((pipe (fn (x) (+ x 1)) (fn (x) (* x 3))) 0)\n= 3\n\nShould compose nested closures\n> ((pipe (fn (x) ((pipe (fn (x) x) (fn (x) x)) x)) (fn (x) (* x 4))) 1)\n= 4\n\nShould compose two partially applied functions together\n| (def add (x y) (+ x y))\n> ((pipe (add 2) (add 4)) -1)\n= 5\n\nShould isolate lambdas syntacticly\n| (typ (maybe a) (Some a) None)\n| (def f (x) ((pipe (fn (x) (match x (Some y) y None 0)) (fn (x) (Some x))) x))\n> (match (f (Some 6)) (Some x) x None -1)\n= 6\n\nShould not shadow symbols\n| (def x (a b) (+ a b))\n> ((pipe (x 2) (x 4)) -1)\n= 5\n", "features": {"programming language": ["Clojure"], "workflow": ["define functions", "compose functions", "execute pipeline"], "implementation style": ["functional"], "functionality": ["function composition"], "resource usage": [], "computation operation": {"mathematical operation": ["addition", "division", "multiplication"], "algorithmic operation": ["function application"]}, "security": [], "user interaction": [], "data processing": {"data transformation": ["increment value", "divide by 2", "multiply by 3", "multiply by 4", "add values"]}, "file operation": [], "error handling": [], "logging": [], "dependency relations": [], "algorithm": ["function composition"], "data structures": ["function", "closure"], "implementation logic": ["composition", "nested function calls"], "advanced techniques": [], "issues & bugs": [], "potential scenario": "The code is used to create a pipeline of composed functions for mathematical operations.", "summary": "Defines and composes multiple functions and closures to create a pipeline for processing numerical inputs through a series of transformations.", "purpose": "To demonstrate the composition of functions and closures in Clojure for sequential data processing."}}
{"idx": 4, "original_code": "a = 1 / 0\n", "features": {"programming language": ["Python"], "workflow": [], "implementation style": ["procedural"], "functionality": ["computation"], "resource usage": ["CPU Cycles"], "computation operation": {"mathematical operation": ["division"]}, "security": [], "user interaction": [], "data processing": [], "file operation": [], "error handling": ["exception management"], "logging": [], "dependency relations": [], "algorithm": [], "data structures": ["variable"], "implementation logic": ["conditional"], "advanced techniques": [], "issues & bugs": ["potential division by zero"], "potential scenario": "The code attempts to perform a division operation, which leads to a division by zero error.", "summary": "Attempts to perform a division operation that results in a division by zero error.", "purpose": "To perform a division operation, illustrating a potential runtime error."}}
